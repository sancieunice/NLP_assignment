{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtJEJt+6Za7cLL4vGaupcd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvFTDet7eSmJ",
        "outputId": "b230413c-1a02-47e7-9e06-95af6d3154ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: ['artificial', 'intelligence', 'and', 'machine', 'learning', 'are', 'transforming', 'the', 'world', 'of', 'technology', 'and', 'creating', 'new', 'opportunities', 'for', 'innovation', '.']\n",
            "Unigram frequencies: <FreqDist with 17 samples and 18 outcomes>\n",
            "\n",
            "Bigrams: [('artificial', 'intelligence'), ('intelligence', 'and'), ('and', 'machine'), ('machine', 'learning'), ('learning', 'are'), ('are', 'transforming'), ('transforming', 'the'), ('the', 'world'), ('world', 'of'), ('of', 'technology'), ('technology', 'and'), ('and', 'creating'), ('creating', 'new'), ('new', 'opportunities'), ('opportunities', 'for'), ('for', 'innovation'), ('innovation', '.')]\n",
            "Bigram frequencies: <FreqDist with 17 samples and 17 outcomes>\n",
            "\n",
            "Trigrams: [('artificial', 'intelligence', 'and'), ('intelligence', 'and', 'machine'), ('and', 'machine', 'learning'), ('machine', 'learning', 'are'), ('learning', 'are', 'transforming'), ('are', 'transforming', 'the'), ('transforming', 'the', 'world'), ('the', 'world', 'of'), ('world', 'of', 'technology'), ('of', 'technology', 'and'), ('technology', 'and', 'creating'), ('and', 'creating', 'new'), ('creating', 'new', 'opportunities'), ('new', 'opportunities', 'for'), ('opportunities', 'for', 'innovation'), ('for', 'innovation', '.')]\n",
            "Trigram frequencies: <FreqDist with 16 samples and 16 outcomes>\n",
            "\n",
            "Bigram probabilities:\n",
            "P(intelligence|artificial) = 1.0\n",
            "P(and|intelligence) = 1.0\n",
            "P(machine|and) = 0.5\n",
            "P(creating|and) = 0.5\n",
            "P(learning|machine) = 1.0\n",
            "P(are|learning) = 1.0\n",
            "P(transforming|are) = 1.0\n",
            "P(the|transforming) = 1.0\n",
            "P(world|the) = 1.0\n",
            "P(of|world) = 1.0\n",
            "P(technology|of) = 1.0\n",
            "P(and|technology) = 1.0\n",
            "P(new|creating) = 1.0\n",
            "P(opportunities|new) = 1.0\n",
            "P(for|opportunities) = 1.0\n",
            "P(innovation|for) = 1.0\n",
            "P(.|innovation) = 1.0\n",
            "\n",
            "Next word prediction for 'this': None\n",
            "\n",
            "Next word prediction for 'a': None\n",
            "\n",
            "Next word prediction for 'for': innovation\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, FreqDist\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"Artificial intelligence and machine learning are transforming the world of technology and creating new opportunities for innovation.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# 1. Unigrams\n",
        "unigrams = tokens\n",
        "unigram_freq = FreqDist(unigrams)\n",
        "\n",
        "print(\"Unigrams:\", unigrams)\n",
        "print(\"Unigram frequencies:\", unigram_freq)\n",
        "\n",
        "# 2. Bigrams\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "bigram_freq = FreqDist(bigrams)\n",
        "\n",
        "print(\"\\nBigrams:\", bigrams)\n",
        "print(\"Bigram frequencies:\", bigram_freq)\n",
        "\n",
        "# 3. Trigrams\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "trigram_freq = FreqDist(trigrams)\n",
        "\n",
        "print(\"\\nTrigrams:\", trigrams)\n",
        "print(\"Trigram frequencies:\", trigram_freq)\n",
        "\n",
        "# 4. Bigram probabilities\n",
        "bigram_prob = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "for w1, w2 in bigrams:\n",
        "    bigram_prob[w1][w2] += 1\n",
        "\n",
        "for w1 in bigram_prob:\n",
        "    total_count = float(sum(bigram_prob[w1].values()))\n",
        "    for w2 in bigram_prob[w1]:\n",
        "        bigram_prob[w1][w2] /= total_count\n",
        "\n",
        "print(\"\\nBigram probabilities:\")\n",
        "for w1 in bigram_prob:\n",
        "    for w2 in bigram_prob[w1]:\n",
        "        print(f\"P({w2}|{w1}) = {bigram_prob[w1][w2]}\")\n",
        "\n",
        "# 5. Next word prediction\n",
        "def predict_next_word(current_word):\n",
        "    if current_word in bigram_prob:\n",
        "        next_word = max(bigram_prob[current_word], key=bigram_prob[current_word].get)\n",
        "        return next_word\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example predictions\n",
        "current_words = [\"this\", \"a\", \"for\"]\n",
        "for word in current_words:\n",
        "    next_word = predict_next_word(word)\n",
        "    print(f\"\\nNext word prediction for '{word}': {next_word}\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}