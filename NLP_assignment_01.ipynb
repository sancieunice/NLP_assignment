{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw0E8YYmcE1qocVQkNec1+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvFTDet7eSmJ",
        "outputId": "c5924814-fd55-4c29-aa3f-aebd9c237e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: ['machine', 'learning', 'models', 'are', 'used', 'for', 'predictive', 'analytics', '.', 'predictive', 'analytics', 'is', 'important', 'in', 'data', 'science', '.', 'data', 'science', 'involves', 'machine', 'learning', 'models', '.']\n",
            "Unigram frequencies: <FreqDist with 15 samples and 24 outcomes>\n",
            "\n",
            "Bigrams: [('machine', 'learning'), ('learning', 'models'), ('models', 'are'), ('are', 'used'), ('used', 'for'), ('for', 'predictive'), ('predictive', 'analytics'), ('analytics', '.'), ('.', 'predictive'), ('predictive', 'analytics'), ('analytics', 'is'), ('is', 'important'), ('important', 'in'), ('in', 'data'), ('data', 'science'), ('science', '.'), ('.', 'data'), ('data', 'science'), ('science', 'involves'), ('involves', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', '.')]\n",
            "Bigram frequencies: <FreqDist with 19 samples and 23 outcomes>\n",
            "\n",
            "Trigrams: [('machine', 'learning', 'models'), ('learning', 'models', 'are'), ('models', 'are', 'used'), ('are', 'used', 'for'), ('used', 'for', 'predictive'), ('for', 'predictive', 'analytics'), ('predictive', 'analytics', '.'), ('analytics', '.', 'predictive'), ('.', 'predictive', 'analytics'), ('predictive', 'analytics', 'is'), ('analytics', 'is', 'important'), ('is', 'important', 'in'), ('important', 'in', 'data'), ('in', 'data', 'science'), ('data', 'science', '.'), ('science', '.', 'data'), ('.', 'data', 'science'), ('data', 'science', 'involves'), ('science', 'involves', 'machine'), ('involves', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', '.')]\n",
            "Trigram frequencies: <FreqDist with 21 samples and 22 outcomes>\n",
            "\n",
            "Bigram probabilities:\n",
            "P(learning|machine) = 1.0\n",
            "P(models|learning) = 1.0\n",
            "P(are|models) = 0.5\n",
            "P(.|models) = 0.5\n",
            "P(used|are) = 1.0\n",
            "P(for|used) = 1.0\n",
            "P(predictive|for) = 1.0\n",
            "P(analytics|predictive) = 1.0\n",
            "P(.|analytics) = 0.5\n",
            "P(is|analytics) = 0.5\n",
            "P(predictive|.) = 0.5\n",
            "P(data|.) = 0.5\n",
            "P(important|is) = 1.0\n",
            "P(in|important) = 1.0\n",
            "P(data|in) = 1.0\n",
            "P(science|data) = 1.0\n",
            "P(.|science) = 0.5\n",
            "P(involves|science) = 0.5\n",
            "P(machine|involves) = 1.0\n",
            "\n",
            "Next word prediction for 'predictive': analytics\n",
            "\n",
            "Next word prediction for 'machine': learning\n",
            "\n",
            "Next word prediction for 'data': science\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, FreqDist\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"Machine learning models are used for predictive analytics. Predictive analytics is important in data science. Data science involves machine learning models.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# 1. Unigrams\n",
        "unigrams = tokens\n",
        "unigram_freq = FreqDist(unigrams)\n",
        "\n",
        "print(\"Unigrams:\", unigrams)\n",
        "print(\"Unigram frequencies:\", unigram_freq)\n",
        "\n",
        "# 2. Bigrams\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "bigram_freq = FreqDist(bigrams)\n",
        "\n",
        "print(\"\\nBigrams:\", bigrams)\n",
        "print(\"Bigram frequencies:\", bigram_freq)\n",
        "\n",
        "# 3. Trigrams\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "trigram_freq = FreqDist(trigrams)\n",
        "\n",
        "print(\"\\nTrigrams:\", trigrams)\n",
        "print(\"Trigram frequencies:\", trigram_freq)\n",
        "\n",
        "# 4. Bigram probabilities\n",
        "bigram_prob = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "for w1, w2 in bigrams:\n",
        "    bigram_prob[w1][w2] += 1\n",
        "\n",
        "for w1 in bigram_prob:\n",
        "    total_count = float(sum(bigram_prob[w1].values()))\n",
        "    for w2 in bigram_prob[w1]:\n",
        "        bigram_prob[w1][w2] /= total_count\n",
        "\n",
        "print(\"\\nBigram probabilities:\")\n",
        "for w1 in bigram_prob:\n",
        "    for w2 in bigram_prob[w1]:\n",
        "        print(f\"P({w2}|{w1}) = {bigram_prob[w1][w2]}\")\n",
        "\n",
        "# 5. Next word prediction\n",
        "def predict_next_word(current_word):\n",
        "    if current_word in bigram_prob:\n",
        "        next_word = max(bigram_prob[current_word], key=bigram_prob[current_word].get)\n",
        "        return next_word\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example predictions\n",
        "current_words = [\"predictive\", \"machine\", \"data\"]\n",
        "for word in current_words:\n",
        "    next_word = predict_next_word(word)\n",
        "    print(f\"\\nNext word prediction for '{word}': {next_word}\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}