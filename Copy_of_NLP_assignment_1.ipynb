{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIz6VJ2F/QYIMezIl5xy4K"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhsFA0fOP4di",
        "outputId": "35b75475-573f-457f-f1ec-4a54b9332743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: ['this', 'is', 'a', 'sample', 'text', 'corpus', 'for', 'generating', 'unigrams', ',', 'bigrams', ',', 'trigrams', 'and', 'for', 'predicting', 'the', 'next', 'word', '.']\n",
            "Unigram frequencies: <FreqDist with 18 samples and 20 outcomes>\n",
            "\n",
            "Bigrams: [('this', 'is'), ('is', 'a'), ('a', 'sample'), ('sample', 'text'), ('text', 'corpus'), ('corpus', 'for'), ('for', 'generating'), ('generating', 'unigrams'), ('unigrams', ','), (',', 'bigrams'), ('bigrams', ','), (',', 'trigrams'), ('trigrams', 'and'), ('and', 'for'), ('for', 'predicting'), ('predicting', 'the'), ('the', 'next'), ('next', 'word'), ('word', '.')]\n",
            "Bigram frequencies: <FreqDist with 19 samples and 19 outcomes>\n",
            "\n",
            "Trigrams: [('this', 'is', 'a'), ('is', 'a', 'sample'), ('a', 'sample', 'text'), ('sample', 'text', 'corpus'), ('text', 'corpus', 'for'), ('corpus', 'for', 'generating'), ('for', 'generating', 'unigrams'), ('generating', 'unigrams', ','), ('unigrams', ',', 'bigrams'), (',', 'bigrams', ','), ('bigrams', ',', 'trigrams'), (',', 'trigrams', 'and'), ('trigrams', 'and', 'for'), ('and', 'for', 'predicting'), ('for', 'predicting', 'the'), ('predicting', 'the', 'next'), ('the', 'next', 'word'), ('next', 'word', '.')]\n",
            "Trigram frequencies: <FreqDist with 18 samples and 18 outcomes>\n",
            "\n",
            "Bigram probabilities:\n",
            "P(is|this) = 1.0\n",
            "P(a|is) = 1.0\n",
            "P(sample|a) = 1.0\n",
            "P(text|sample) = 1.0\n",
            "P(corpus|text) = 1.0\n",
            "P(for|corpus) = 1.0\n",
            "P(generating|for) = 0.5\n",
            "P(predicting|for) = 0.5\n",
            "P(unigrams|generating) = 1.0\n",
            "P(,|unigrams) = 1.0\n",
            "P(bigrams|,) = 0.5\n",
            "P(trigrams|,) = 0.5\n",
            "P(,|bigrams) = 1.0\n",
            "P(and|trigrams) = 1.0\n",
            "P(for|and) = 1.0\n",
            "P(the|predicting) = 1.0\n",
            "P(next|the) = 1.0\n",
            "P(word|next) = 1.0\n",
            "P(.|word) = 1.0\n",
            "\n",
            "Next word prediction for 'this': is\n",
            "\n",
            "Next word prediction for 'a': sample\n",
            "\n",
            "Next word prediction for 'for': generating\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, FreqDist\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"This is a sample text corpus for generating unigrams, bigrams, trigrams and for predicting the next word.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# 1. Unigrams\n",
        "unigrams = tokens\n",
        "unigram_freq = FreqDist(unigrams)\n",
        "\n",
        "print(\"Unigrams:\", unigrams)\n",
        "print(\"Unigram frequencies:\", unigram_freq)\n",
        "\n",
        "# 2. Bigrams\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "bigram_freq = FreqDist(bigrams)\n",
        "\n",
        "print(\"\\nBigrams:\", bigrams)\n",
        "print(\"Bigram frequencies:\", bigram_freq)\n",
        "\n",
        "# 3. Trigrams\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "trigram_freq = FreqDist(trigrams)\n",
        "\n",
        "print(\"\\nTrigrams:\", trigrams)\n",
        "print(\"Trigram frequencies:\", trigram_freq)\n",
        "\n",
        "# 4. Bigram probabilities\n",
        "bigram_prob = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "for w1, w2 in bigrams:\n",
        "    bigram_prob[w1][w2] += 1\n",
        "\n",
        "for w1 in bigram_prob:\n",
        "    total_count = float(sum(bigram_prob[w1].values()))\n",
        "    for w2 in bigram_prob[w1]:\n",
        "        bigram_prob[w1][w2] /= total_count\n",
        "\n",
        "print(\"\\nBigram probabilities:\")\n",
        "for w1 in bigram_prob:\n",
        "    for w2 in bigram_prob[w1]:\n",
        "        print(f\"P({w2}|{w1}) = {bigram_prob[w1][w2]}\")\n",
        "\n",
        "# 5. Next word prediction\n",
        "def predict_next_word(current_word):\n",
        "    if current_word in bigram_prob:\n",
        "        next_word = max(bigram_prob[current_word], key=bigram_prob[current_word].get)\n",
        "        return next_word\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example predictions\n",
        "current_words = [\"this\", \"a\", \"for\"]\n",
        "for word in current_words:\n",
        "    next_word = predict_next_word(word)\n",
        "    print(f\"\\nNext word prediction for '{word}': {next_word}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xni6e-69QO9w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}